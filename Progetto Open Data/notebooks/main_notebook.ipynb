{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d4893ee6",
   "metadata": {},
   "source": [
    "# <center> **Tesina di Open Data Management 2022-2023**\n",
    "\n",
    "<br>\n",
    "<div align=\"center\">\n",
    "    <img src=\"op_wallpaper.jpg\" width=\"1200\" height=\"auto\">\n",
    "\n",
    "### <center> _Andrea Spinelli, Raffaele Terracino, Marco Valenti_\n",
    "##### <center> 23 Giugno \n",
    "\n",
    "***\n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4ed5dffb",
   "metadata": {},
   "source": [
    "# __Indice__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f4687743",
   "metadata": {},
   "source": [
    "###  [`1. Traccia`](#)\n",
    "### [`2. Selezione dei dataset`](#)\n",
    "##### &emsp;&emsp; [`2.1 Raccolta`](#)\n",
    "##### &emsp;&emsp; [`2.2 Licenze`](#)\n",
    "### [`3. Elaborazione dei dataset`](#)\n",
    "##### &emsp;&emsp; [`3.1 Pulizia e selezione dei dati rilevanti`](#)\n",
    "##### &emsp;&emsp; [`3.2 Arricchimento`](#)\n",
    "### [`4. Trasformazione dei dataset a 5 stelle`](#)\n",
    "##### &emsp;&emsp; [`4.1 Ontologia`](#)\n",
    "##### &emsp;&emsp; [`4.2 Creazione grafo RDF`](#)\n",
    "##### &emsp;&emsp; [`4.3 Interlinking del grafo RDF`](#)\n",
    "### [`5. Data visualization`](#)\n",
    "### [`6. Creazione di un'applicazione`](#)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a21597c8",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# __1 Traccia__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cb5b2ab5",
   "metadata": {},
   "source": [
    "<u> Utilizzando il linguaggio Python, per lo sviluppo del progetto si devono innanzitutto rispettare i seguenti passi: </u>\n",
    "\n",
    "- _Selezione dati;_\n",
    "- _Elaborazione dati (data cleaning, definizione struttura omogenea);_\n",
    "- _Open Linked Data (creazione di uno strato semantico, ontologie, interlinking)._\n",
    " \n",
    "<u> Dopodich√© si pu√≤ passare, opzionalmente, allo sviluppo del servizio tramite: </u> \n",
    "- _Creazione di un bot telegram._\n",
    "\n",
    "<u> Siano i seguenti dataset (forniti in allegato): </u>\n",
    "\n",
    "__farmacie.csv,__\n",
    "\n",
    "__parafarmacie.csv,__\n",
    "\n",
    "__strutture_sanitarie_pubbliche.csv,__\n",
    "\n",
    "__strutture_sanitarie_private.csv.__\n",
    "\n",
    "<u> Si vuole realizzare un servizio in ambito ‚ÄúSalute‚Äù che fornisca le posizioni e le disponibilit√† delle strutture mediche nella regione siciliana. </u>\n",
    "\n",
    "Si suppone che un utente del servizio abbia bisogno di dover andare a fare una visita dermatologica (struttura privata), oppure una visita ad un consultorio (struttura pubblica), tuttavia non conosce la posizione della struttura; quindi, pu√≤ interrogare il servizio affinch√© possa trovare in un raggio di ùë• metri, data la sua posizione, un elenco (messaggio testuale, posizioni, ‚Ä¶) di strutture specializzate nel campo desiderato. \n",
    "\n",
    "√à possibile inoltre che l‚Äôutente, dopo una visita, abbia la prescrizione di alcuni farmaci; pertanto, avr√† bisogno della locazione delle farmacie, o parafarmacie, pi√π vicine. Il servizio di tale richiesta funziona allo stesso modo di quello precedente, inoltre si pu√≤ fornire anche il recapito telefonico per effettuare la prenotazione dei farmaci. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0902fd99",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# __2 Selezione dei dataset__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6624065d",
   "metadata": {},
   "source": [
    "\n",
    "### __2.1 Raccolta__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "958660ca",
   "metadata": {},
   "source": [
    "I dataset utilizzati per la realizzazione della base di conoscenza riguardano Farmacie, Parafarmacie, Strutture sanitarie Pubbliche, Strutture Sanitarie Private e la Popolazione residente in Sicilia nell'anno 2023. L'obiettivo della base di conoscenza √® racchiudere tutti gli esercizi sanitari presenti in Sicilia.\n",
    "\n",
    "L'ultimo dataset, in particolare, risulta fondamentale per raccontare una storia basandosi sugli altri dataset.\n",
    "\n",
    "Seguono i link da cui sono stati reperiti i dataset\n",
    "\n",
    "`Farmacie:` <br>\n",
    "_https://www.dati.salute.gov.it/dati/dettaglioDataset.jsp?menu=dati&idPag=5_\n",
    "\n",
    "`Parafarmacie:` <br>\n",
    "_https://www.dati.salute.gov.it/dati/dettaglioDataset.jsp?menu=dati&idPag=7_\n",
    "\n",
    "`Strutture Sanitarie Pubbliche:` <br>\n",
    "_https://dati.regione.sicilia.it/catalogo/da5a0f1f-82b4-472f-b3dd-458295983a97_\n",
    "\n",
    "`Strutture Sanitarie Private:` <br>\n",
    "_http://pti.regione.sicilia.it/portal/page/portal/PIR_PORTALE/PIR_LaStrutturaRegionale/PIR_AssessoratoSalute/PIR_DipPianificazioneStrategica/PIR_Infoedocumenti/PIR_8713479.360776903/PIR_Strutturesanitarieprivateaccreditate_\n",
    "\n",
    "`Popolazione Sicilia, 1 Gen 2023:` <br>\n",
    "_http://dati.istat.it/Index.aspx?QueryId=19101_\n",
    "\n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ed748f4b",
   "metadata": {},
   "source": [
    "### __2.2 Licenze__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1a477323",
   "metadata": {},
   "source": [
    "`Farmacie:` Italian Open Data Licence v2.0\n",
    "\n",
    "`Parafarmacie:` Italian Open Data Licence v2.0\n",
    "\n",
    "`Strutture Sanitarie Pubbliche:` Creative Commons BY, versione 4.0\n",
    "\n",
    "`Strutture Sanitarie Private:` Licenza specificata nel decreto legislativo n. 33/2013, che specifica che \"documenti, le informazioni e i dati oggetto di pubblicazione obbligatoria ai sensi della normativa vigente, resi disponibili anche a seguito dell'accesso civico di cui all'articolo 5, sono pubblicati in formato di tipo aperto ai sensi dell'articolo 68 del Codice dell'amministrazione digitale, di cui al decreto legislativo 7 marzo 2005, n. 82, e sono riutilizzabili ai sensi del decreto legislativo 24 gennaio 2006, n. 36, del decreto legislativo 7 marzo 2005, n. 82, e del decreto legislativo 30 giugno 2003, n. 196, senza ulteriori restrizioni diverse dall'obbligo di citare la fonte e di rispettarne l'integrit√†\"\n",
    "\n",
    "`Popolazione Sicilia, 1 Gen 2023:` Creative Commons BY, versione 3.0 (specificato al link https://www.istat.it/it/note-legali)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ab935cc9",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# __3 Elaborazione dei dataset__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "19c195a9",
   "metadata": {},
   "source": [
    "### __3.1 Pulizia e selezione dei dati rilevanti__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8eb5aec9",
   "metadata": {},
   "source": [
    "Si √® notato innanzitutto che i dataset puri non erano tutti adatti allo stesso modo, infatti, si sono riscontrate due problematiche:\n",
    "1. Encoding dei dataset differenti, a causa delle loro diversi origini;\n",
    "2. Errori vari dovuti a `;` o `,` non correttamente inseriti.\n",
    "\n",
    "La problematica 1. si √® riscontrata a causa degli errori di lettura dei file `CSV` da parte del metodo `read_csv()` di `Pandas`, inoltre se ne √® veriificata la veridicit√† tramite il comando `file` di Unix.<br>\n",
    "Per ovviare a tale problema si √® deciso prima di tutto come encoding pi√π adatto ai dataset scelti l'`UTF-8`, dopodich√© si √® passati alla conversione dell'encoding dei file tramite un convertitore online che, in quanto i file `CSV` sono alla base dei testi, non ha generato problemi problemi di conversione nei dataset.\n",
    "\n",
    "La problematica 2. si √® riscontrata tramite lettura e osservazioni preventive all'uso dei dataset, i quali quest'ultimi presentavano errori di compiliazioni facilmente individuabili, appunto, si √® fatto semplice uso dello strumento `Find and Replace`.\n",
    "\n",
    "Gli strumenti adoperati per la pulizia dei dataset includono `frictionless`, `Open Refine`, l'estensione `Edit csv` di `VS Code` e `Microsoft Excel`.\n",
    "\n",
    "I dataset relativi a questa prima elaborazione sono stati raccolti in: `../datasets/cleaned/`. <br>\n",
    "\n",
    "Proseguendo con l'elaborazione dei dataset, sono seguite altre due osservazioni:\n",
    "1. Alcune **righe** dei dataset presentano dati di regioni aggiuntive oltre la Sicilia (a cui √® stato circoscritto il progetto);\n",
    "2. Siccome i dataset sono circoscritti ad una regione, alcune **colonne** ripetevano un medesimo dato per tutti i dataset.\n",
    "\n",
    "Entrambe le osservazioni sono state ovviate sempre in fase di pre-processing mediante lo strumento `Excel`. <br>\n",
    "La 1. selezionando le righe cui presentavano il campo \"Regione = Sicilia\" e rimuovendo le altre; la 2., similmente, eliminando direttamente i campi superflui pi√π quelli non adatti allo scopo del progetto.\n",
    "\n",
    "Questa seconda elaborazione dei dataset √® stata riportata in: `../datasets/pivoted/`.\n",
    "\n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "977d6e85",
   "metadata": {},
   "source": [
    "### __3.2 Arricchimento__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ea9d3123",
   "metadata": {},
   "source": [
    "Successiva alla fase di pulizia e selezione, si √® introdotta una fase di arricchimento dei dataset.\n",
    "\n",
    "Tale scelta √® stata effettuata dopo varie osservazioni preventive per le fasi successive dei dataset, i motivi principi sono stati: <br>\n",
    "l'agevolazione della trasformazione dei dataset a 4 stelle nel formato RDF, <br>\n",
    "l'agevolazione della trasformazione dei dataset a 5 stelle per l'interlinking."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7982bf45",
   "metadata": {},
   "source": [
    "Per quest'ultima fase si √® fatto uso della libreria `OSMPythonTools.nominatim` che offre la possibilit√† di fare richiesta ai database di OpenStreetMap, inoltre fornisce un servizio di caching molto vantaggioso all'uso in quanto, fatta una serie di richieste, scarica e salva tutti i dati in una cartella a parte che, in caso di riavvio del programma, riduce il tempo dello script localmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15fbd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "comuni = pd.read_csv(\"../datasets/csv/selected/popolazione_sicilia.csv\", sep=',', skiprows=[1])\n",
    "farmacie = pd.read_csv('../datasets/csv/cleaned/farmacie.csv', sep=';') #si prende quello clenead per considerare pi√π comuni\n",
    "\n",
    "comuni['Territorio'] = comuni['Territorio'].apply(lambda x : x.title().replace('√†', 'a\\'').replace('√®', 'e\\'').replace('√¨', 'i\\'').replace('√≤', 'o\\'').replace('√π', 'u\\''))\n",
    "farmacie['DESCRIZIONECOMUNE'] = farmacie['DESCRIZIONECOMUNE'].apply(lambda x : x.title())\n",
    "joined = comuni.merge(farmacie, left_on='Territorio', right_on='DESCRIZIONECOMUNE')\n",
    "\n",
    "df2=joined.drop_duplicates(subset=['Territorio'], keep='first')\n",
    "\n",
    "df3=df2.rename(columns={\"Territorio\": \"Comune\", \"Value\": \"PopolazioneTotale\", \"DESCRIZIONEPROVINCIA\" : \"Provincia\", \"SIGLAPROVINCIA\":\"SiglaProvincia\"})\n",
    "df3.to_csv('comuni_sicilia.csv', columns=['Comune', 'PopolazioneTotale', 'Provincia', 'SiglaProvincia'], index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "89245350",
   "metadata": {},
   "source": [
    "Inizializzazione dei dataset da arricchire in delle variabili:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e305354",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_private = pd.read_csv(\"../datasets/csv/selected/strutture_sanitarie_private.csv\", on_bad_lines=\"skip\", delimiter=\";\", encoding=\"utf-8\")\n",
    "df_pubbliche = pd.read_csv(\"../datasets/csv/selected/strutture_sanitarie_pubbliche.csv\", on_bad_lines=\"skip\", delimiter=\";\", encoding=\"utf-8\")\n",
    "df_farma = pd.read_csv(\"../datasets/csv/selected/farmacie.csv\", on_bad_lines=\"skip\", delimiter=\",\", encoding=\"utf-8\")\n",
    "\n",
    "df_private.columns = df_private.columns.str.strip()\n",
    "df_pubbliche.columns = df_pubbliche.columns.str.strip()\n",
    "df_farma.columns = df_farma.columns.str.strip()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f75e2680",
   "metadata": {},
   "source": [
    "Si arricchisce `private.csv` con `CAP`, `Latitudine` e `Longitudine`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255ab5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from OSMPythonTools.nominatim import Nominatim\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "nominatim = Nominatim()\n",
    "results = []\n",
    "\n",
    "LOC = []\n",
    "LAT = []\n",
    "LON = []\n",
    "\n",
    "for via, citta in zip(df_private[\"Indirizzo\"], df_private[\"Citta\\'\"]):\n",
    "    \n",
    "    via = str(via).lower().replace('a\\'', 'a').replace('e\\'', 'e').replace('i\\'', 'i').replace('o\\'', 'o').replace('u\\'', 'u')\n",
    "    citta = str(citta).lower().replace('a\\'', 'a').replace('e\\'', 'e').replace('i\\'', 'i').replace('o\\'', 'o').replace('u\\'', 'u')\n",
    "\n",
    "    res = nominatim.query(via + \" \" + citta)\n",
    "    results.append(res)\n",
    "\n",
    "for item in results:\n",
    "    tmp = item.toJSON()\n",
    "    if len(tmp) != 0:\n",
    "        LAT.append(tmp[0]['lat'])\n",
    "        LON.append(tmp[0]['lon'])\n",
    "        cap = re.search(r'\\d{5}',tmp[0]['display_name'])\n",
    "        if cap is not None:\n",
    "            LOC.append(cap.group())\n",
    "        else:\n",
    "            LOC.append(0)\n",
    "    else:\n",
    "        LAT.append(0.0)\n",
    "        LON.append(0.0)\n",
    "        LOC.append(0)\n",
    "            \n",
    "df_private.insert(loc=0, column='Longitudine', value=pd.Series(LON))\n",
    "df_private.insert(loc=0, column='Latitudine', value=pd.Series(LAT))\n",
    "df_private.insert(loc=0, column='CAP', value=pd.Series(LOC))\n",
    "\n",
    "filepath = Path('../datasets/csv/completed/private.csv')\n",
    "df_private.to_csv(filepath, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4ed39b14",
   "metadata": {},
   "source": [
    "Si arricchisce `pubbliche.csv` con `Comune`, `Latitudine` e `Longitudine`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640fd973",
   "metadata": {},
   "outputs": [],
   "source": [
    "from OSMPythonTools.nominatim import Nominatim\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "nominatim = Nominatim()\n",
    "results = []\n",
    "\n",
    "COM = []\n",
    "LAT = []\n",
    "LON = []\n",
    "\n",
    "for via, cap in zip(df_pubbliche[\"Indirizzo\"], df_pubbliche[\"CAP\"]):\n",
    "    \n",
    "    via = str(via).lower().replace('a\\'', 'a').replace('e\\'', 'e').replace('i\\'', 'i').replace('o\\'', 'o').replace('u\\'', 'u')\n",
    "    cap = str(cap).lower().replace('a\\'', 'a').replace('e\\'', 'e').replace('i\\'', 'i').replace('o\\'', 'o').replace('u\\'', 'u')\n",
    "\n",
    "    res = nominatim.query(via + \" \" + cap)\n",
    "    results.append(res)\n",
    "    \n",
    "for item in results:\n",
    "    tmp = item.toJSON()\n",
    "    if len(tmp) != 0:\n",
    "        LAT.append(tmp[0]['lat'])\n",
    "        LON.append(tmp[0]['lon'])\n",
    "        com = re.search(r', (\\w*), Sicilia',tmp[0]['display_name'])\n",
    "        if com is not None:\n",
    "            COM.append(com[1])\n",
    "        else:\n",
    "            COM.append(\"\")\n",
    "    else:\n",
    "        LAT.append(0.0)\n",
    "        LON.append(0.0)\n",
    "        COM.append(\"\")\n",
    "            \n",
    "df_pubbliche.insert(loc=0, column='Longitudine', value=pd.Series(LON))\n",
    "df_pubbliche.insert(loc=0, column='Latitudine', value=pd.Series(LAT))\n",
    "df_pubbliche.insert(loc=0, column='Comune', value=pd.Series(COM))\n",
    "\n",
    "filepath = Path('../datasets/csv/completed/pubbliche.csv')\n",
    "df_pubbliche.to_csv(filepath, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eab42d63",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Si rielaborano i campi `LATITUDINE` e `LONGITUDINE` di `farmacie.csv`, in quanto le ultime due centinaia dei campi mancano di informazioni. <br>\n",
    "Si inseriscono in un CSV temporaneo i dati mancanti, si rielaborano allo stesso modo dei due file precedenti, sovracrivendo i campi esistenti, e si concatenato con quello originale:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c78505fe",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from OSMPythonTools.nominatim import Nominatim\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "df_farma_tmp = pd.read_csv(\"../datasets/csv/selected/farmacie_tmp.csv\", on_bad_lines=\"skip\", encoding=\"utf-8\")\n",
    "\n",
    "nominatim = Nominatim()\n",
    "results = []\n",
    "\n",
    "LAT = []\n",
    "LON = []\n",
    "\n",
    "for via, citta in zip(df_farma_tmp[\"INDIRIZZO\"], df_farma_tmp[\"DESCRIZIONECOMUNE\"]):\n",
    "\n",
    "    via = str(via).lower().replace('a\\'', 'a').replace('e\\'', 'e').replace('i\\'', 'i').replace('o\\'', 'o').replace('u\\'', 'u')\n",
    "    citta = str(citta).lower().replace('a\\'', 'a').replace('e\\'', 'e').replace('i\\'', 'i').replace('o\\'', 'o').replace('u\\'', 'u')\n",
    "\n",
    "    res = nominatim.query(via + \",\" + citta)\n",
    "    results.append(res)\n",
    "\n",
    "for item in results:\n",
    "    tmp = item.toJSON()\n",
    "    if len(tmp) != 0:\n",
    "        LAT.append(tmp[0]['lat'])\n",
    "        LON.append(tmp[0]['lon'])\n",
    "    else:\n",
    "        LAT.append(0.0)\n",
    "        LON.append(0.0)\n",
    "\n",
    "df_farma_tmp[\"LONGITUDINE\"] = pd.Series(LON)\n",
    "df_farma_tmp[\"LATITUDINE\"] = pd.Series(LAT)\n",
    "\n",
    "###\n",
    "\n",
    "df_farma[\"LATITUDINE\"] = df_farma[\"LATITUDINE\"].apply(lambda x : float(x.replace(',', '.')) if x != '-' else 0.0)\n",
    "df_farma[\"LONGITUDINE\"] = df_farma[\"LONGITUDINE\"].apply(lambda x : float(x.replace(',', '.')) if x != '-' else 0.0)\n",
    "df_farma[\"PARTITAIVA\"] = df_farma[\"PARTITAIVA\"].apply(lambda x : x if x != \"-\" else 0)\n",
    "df_farma[\"INDIRIZZO\"] = df_farma[\"INDIRIZZO\"].apply(lambda x : x.replace('\"', ''))\n",
    "\n",
    "filepath = Path('../datasets/csv/selected/tmp.csv')\n",
    "df_farma_tmp.to_csv(filepath, index=False)\n",
    "df_farma_tmp = pd.read_csv(\"../datasets/csv/selected/tmp.csv\", on_bad_lines=\"skip\", encoding=\"utf-8\")\n",
    "\n",
    "###\n",
    "\n",
    "df_farma = df_farma.convert_dtypes()\n",
    "df_farma_tmp = df_farma_tmp.convert_dtypes()\n",
    "\n",
    "df_farma = df_farma.drop(df_farma.loc[448:].index)\n",
    "df_finale = pd.merge(df_farma, df_farma_tmp, how=\"outer\")\n",
    "\n",
    "filepath = Path('../datasets/csv/completed/farmacie.csv')\n",
    "df_finale.to_csv(filepath, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1d924da1",
   "metadata": {},
   "source": [
    "Il salvataggio del dataset con i tipi corretti in un ulteriore file temporaneo √® necessario per il corretto funzionamento per il merge con Pandas."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "92da4f91",
   "metadata": {},
   "source": [
    "Quest'ultime elaborazioni dei dataset sono state riportate in: `../datasets/completed/`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8a8e1e15",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# __4 Trasformazione dei dataset a 5 stelle__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "804fec58",
   "metadata": {},
   "source": [
    "### __4.1 Ontologia__\n",
    "L'ontologia √® stata creata con il software Prot√®g√®..... ontologia_sanita.ttl\n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "598e06ae",
   "metadata": {},
   "source": [
    "### __4.2 Creazione grafo RDF__\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "80c8108c",
   "metadata": {},
   "source": [
    "///some comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f7b96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib.parse\n",
    "from rdflib import Graph, Literal, Namespace, URIRef\n",
    "from rdflib.namespace import RDF, RDFS\n",
    "\n",
    "base_uri = \"http://www.sanitasicilia.it/resource/\"\n",
    "g = Graph()\n",
    "\n",
    "sso = Namespace(\"http://www.sanitasicilia.it/ontology/\")\n",
    "g.bind(\"sso\", sso)\n",
    "\n",
    "ssr = Namespace(\"http://www.sanitasicilia.it/resource/\")\n",
    "g.bind(\"ssr\", ssr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5b302e31",
   "metadata": {},
   "source": [
    "///Some comment COMUNI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266baef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def urify(ns, testo):\n",
    "    testo=testo.replace(\" \",\"_\").replace(\"\\'\",\"\")\n",
    "    return ns+urllib.parse.quote(testo)\n",
    "\n",
    "def addTriples(row):\n",
    "    res = URIRef(urify(base_uri, row[0]))\n",
    "    g.add([res, URIRef(RDF.type), URIRef(sso.Comune)])\n",
    "    g.add([res, sso.hasName, Literal(row[0], datatype=XSD.string)])\n",
    "    g.add([res, sso.hasTotalPopulation, Literal(row[1], datatype=XSD.integer)])\n",
    "    g.add([res, sso.hasProvince, Literal(row[2], datatype=XSD.string)])\n",
    "    g.add([res, sso.hasProvinceAcr, Literal(row[3], datatype=XSD.string)])\n",
    "\n",
    "comuni_df = pd.read_csv(\"../datasets/csv/completed/comuni_sicilia.csv\")\n",
    "\n",
    "comuni_df.apply(lambda row : addTriples(row), axis=1)\n",
    "g.serialize(destination='../datasets/rdf/comuni_sicilia.ttl', format='turtle')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5408a0e2",
   "metadata": {},
   "source": [
    "///Some comment FARMACIE E PARAFARMACIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772dae70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addTriples(row):\n",
    "    res = URIRef(urify(base_uri, row[5]))\n",
    "    g.add([res, URIRef(RDF.type), URIRef(sso.Farmacia)])\n",
    "    g.add([res, sso.isIn, URIRef(urify(base_uri, row[2].title()))])\n",
    "    g.add([res, sso.hasCap, Literal(row[3], datatype=XSD.integer)])\n",
    "    g.add([res, sso.hasAddress, Literal(row[4], datatype=XSD.string)])\n",
    "    g.add([res, sso.hasName, Literal(row[5], datatype=XSD.string)])\n",
    "    g.add([res, sso.hasLatitude, Literal(row[6], datatype=XSD.decimal)])\n",
    "    g.add([res, sso.hasLongitude, Literal(row[7], datatype=XSD.decimal)])\n",
    "    g.add([res, sso.hasVatNumber, Literal(row[8], datatype=XSD.integer)])\n",
    "\n",
    "farmacie_df = pd.read_csv(\"../datasets/csv/completed/farmacie.csv\", sep=';')\n",
    "farmacie_df[\"LATITUDINE\"] = farmacie_df[\"LATITUDINE\"].apply(lambda x : float(x.replace(',', '.')) if x != '-' else 0.0)\n",
    "farmacie_df[\"LONGITUDINE\"] = farmacie_df[\"LONGITUDINE\"].apply(lambda x : float(x.replace(',', '.')) if x != '-' else 0.0)\n",
    "farmacie_df[\"PARTITAIVA\"] = farmacie_df[\"PARTITAIVA\"].apply(lambda x : x if x != '-' else 0)\n",
    "\n",
    "parafarmacie_df = pd.read_csv(\"../datasets/csv/completed/parafarmacie.csv\", sep=';')\n",
    "parafarmacie_df[\"LATITUDINE\"] = parafarmacie_df[\"LATITUDINE\"].apply(lambda x : float(x.replace(',', '.')) if x != '-' else 0.0)\n",
    "parafarmacie_df[\"LONGITUDINE\"] = parafarmacie_df[\"LONGITUDINE\"].apply(lambda x : float(x.replace(',', '.')) if x != '-' else 0.0)\n",
    "parafarmacie_df[\"PARTITAIVA\"] = parafarmacie_df[\"PARTITAIVA\"].apply(lambda x : x if x != '-' else 0)\n",
    "\n",
    "g = Graph()\n",
    "farmacie_df.apply(lambda row : addTriples(row), axis=1)\n",
    "g.serialize(destination='../datasets/rdf/farmacie.ttl', format='turtle')\n",
    "\n",
    "g = Graph() #attualmente, per debug rdf separati\n",
    "parafarmacie_df.apply(lambda row : addTriples(row), axis=1)\n",
    "g.serialize(destination='../datasets/rdf/parafarmacie.ttl', format='turtle')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f6aecc33",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "01b41b5b",
   "metadata": {},
   "source": [
    "### __4.3 Interlinking del grafo RDF__\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cd77a4b8",
   "metadata": {},
   "source": [
    "///some comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34950e82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0da33a5a",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# __5 Data visualization__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fdefa721",
   "metadata": {},
   "source": [
    "### <center> **uMap locations**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "66e165c9",
   "metadata": {},
   "source": [
    "\n",
    "<div align = \"center\">\n",
    "\t<table width=\"90%\" style=\"border: hidden;\">\n",
    "\t\t<tbody>\n",
    "\t\t\t<tr style=\"border: hidden;\">\n",
    "\t\t\t\t<td align = \"center\" style=\"border: hidden;\">Farmacie</td>\n",
    "\t\t\t\t<td align = \"center\" style=\"border: hidden;\">Parafarmacie</td>\n",
    "\t\t\t</tr>\n",
    "\t\t\t<tr style=\"border: hidden;\">\n",
    "\t\t\t\t<td class=\"dcf-txt-center\" style=\"border: hidden;\">\n",
    "\t\t\t\t\t<iframe src=\"https://umap.openstreetmap.fr/it/map/farmacie_930881\" width=\"100%\" height=\"400px\"></iframe>\n",
    "\t\t\t\t</td>\n",
    "\t\t\t\t<td class=\"dcf-txt-center\" style=\"border: hidden;\">\n",
    "\t\t\t\t\t<iframe src=\"https://umap.openstreetmap.fr/it/map/parafarmacie_930888\" width=\"100%\" height=\"400px\"></iframe>\n",
    "\t\t\t\t\t</td>\n",
    "\t\t\t</tr>\n",
    "\t\t\t<tr style=\"border: hidden;\">\n",
    "\t\t\t\t<td align = \"center\" style=\"border: hidden;\">Strutture sanitarie pubbliche</td>\n",
    "\t\t\t\t<td align = \"center\" style=\"border: hidden;\">Strutture sanitarie private</td>\n",
    "\t\t\t</tr>\n",
    "\t\t\t<tr style=\"border: hidden;\">\n",
    "\t\t\t\t<td class=\"dcf-txt-center\" style=\"border: hidden;\">\n",
    "\t\t\t\t\t<iframe src=\"https://umap.openstreetmap.fr/it/map/strutture-sanitarie-pubbliche_930890\" width=\"100%\" height=\"400px\"></iframe>\n",
    "\t\t\t\t</td>\n",
    "\t\t\t\t<td class=\"dcf-txt-center\" style=\"border: hidden;\">\n",
    "\t\t\t\t\t<iframe src=\"https://umap.openstreetmap.fr/it/map/strutture-sanitarie-private_930895\" width=\"100%\" height=\"400px\"></iframe>\n",
    "\t\t\t\t\t</td>\n",
    "\t\t\t</tr>\n",
    "\t\t</tbody>\n",
    "\t</table>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "05cf9238",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# __6 Creazione di un'applicazione__\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2e19392e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
