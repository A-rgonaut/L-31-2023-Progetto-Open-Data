{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d4893ee6",
   "metadata": {},
   "source": [
    "# <center> **Progetto di Open Data Management 2022-2023**\n",
    "\n",
    "<br>\n",
    "<div align=\"center\">\n",
    "    <img src=\"op_wallpaper.jpg\" width=\"1200\" height=\"auto\">\n",
    "\n",
    "### <center> _Andrea Spinelli, Raffaele Terracino, Marco Valenti_\n",
    "##### <center> 23 Giugno \n",
    "\n",
    "***\n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4ed5dffb",
   "metadata": {},
   "source": [
    "# __Indice__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f4687743",
   "metadata": {},
   "source": [
    "###  [`1. Traccia`](#)\n",
    "### [`2. Selezione dei dataset`](#)\n",
    "##### &emsp;&emsp; [`2.1 Raccolta`](#)\n",
    "##### &emsp;&emsp; [`2.2 Licenze`](#)\n",
    "### [`3. Elaborazione dei dataset`](#)\n",
    "##### &emsp;&emsp; [`3.1 Pulizia`](#)\n",
    "##### &emsp;&emsp; [`3.2 Pivoting`](#)\n",
    "##### &emsp;&emsp; [`3.3 Arricchimento`](#)\n",
    "### [`4. Trasformazione dei dataset a 5 stelle`](#)\n",
    "##### &emsp;&emsp; [`4.1 Ontologia`](#)\n",
    "##### &emsp;&emsp; [`4.2 Creazione grafo RDF`](#)\n",
    "### [`5. Data visualization`](#)\n",
    "### [`6. Creazione di un'applicazione`](#)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a21597c8",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# __1 Traccia__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cb5b2ab5",
   "metadata": {},
   "source": [
    "<u> Utilizzando il linguaggio Python, per lo sviluppo del progetto si devono innanzitutto rispettare i seguenti passi: </u>\n",
    "\n",
    "- _Selezione dati;_\n",
    "- _Elaborazione dati (data cleaning, definizione struttura omogenea);_\n",
    "- _Open Linked Data (creazione di uno strato semantico, ontologie, interlinking)._\n",
    " \n",
    "<u> Dopodich√© si pu√≤ passare, opzionalmente, allo sviluppo del servizio tramite: </u> \n",
    "- _Creazione di un bot telegram._\n",
    "\n",
    "<u> Siano i seguenti dataset (forniti in allegato): </u>\n",
    "\n",
    "__farmacie.csv,__\n",
    "\n",
    "__parafarmacie.csv,__\n",
    "\n",
    "__strutture_sanitarie_pubbliche.csv,__\n",
    "\n",
    "__strutture_sanitarie_private.csv.__\n",
    "\n",
    "<u> Si vuole realizzare un servizio in ambito ‚ÄúSalute‚Äù che fornisca le posizioni e le disponibilit√† delle strutture mediche nella regione siciliana. </u>\n",
    "\n",
    "Si suppone che un utente del servizio abbia bisogno di dover andare a fare una visita dermatologica (struttura privata), oppure una visita ad un consultorio (struttura pubblica), tuttavia non conosce la posizione della struttura; quindi, pu√≤ interrogare il servizio affinch√© possa trovare in un raggio di ùë• metri, data la sua posizione, un elenco (messaggio testuale, posizioni, ‚Ä¶) di strutture specializzate nel campo desiderato. \n",
    "\n",
    "√à possibile inoltre che l‚Äôutente, dopo una visita, abbia la prescrizione di alcuni farmaci; pertanto, avr√† bisogno della locazione delle farmacie, o parafarmacie, pi√π vicine. Il servizio di tale richiesta funziona allo stesso modo di quello precedente, inoltre si pu√≤ fornire anche il recapito telefonico per effettuare la prenotazione dei farmaci. \n",
    "\n",
    "***\n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0902fd99",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# __2 Selezione dei dataset__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6624065d",
   "metadata": {},
   "source": [
    "\n",
    "### __2.1 Raccolta__\n",
    "\n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ed748f4b",
   "metadata": {},
   "source": [
    "### __2.2 Licenze__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ab935cc9",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# __3 Elaborazione dei dataset__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "19c195a9",
   "metadata": {},
   "source": [
    "### __3.1 Pulizia__\n",
    "\n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3897fad4",
   "metadata": {},
   "source": [
    "### __3.2 Pivoting__\n",
    "\n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "977d6e85",
   "metadata": {},
   "source": [
    "### __3.3 Arricchimento__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ea9d3123",
   "metadata": {},
   "source": [
    "///some comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15fbd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "comuni = pd.read_csv(\"../datasets/popolazione_sicilia.csv\", sep=',', skiprows=[1])\n",
    "farmacie = pd.read_csv('../datasets/synthesized_&_cleaned/farmacie.csv', sep=';')\n",
    "\n",
    "comuni['Territorio'] = comuni['Territorio'].apply(lambda x : x.title().replace('√†', 'a\\'').replace('√®', 'e\\'').replace('√¨', 'i\\'').replace('√≤', 'o\\'').replace('√π', 'u\\''))\n",
    "farmacie['DESCRIZIONECOMUNE'] = farmacie['DESCRIZIONECOMUNE'].apply(lambda x : x.title())\n",
    "joined = comuni.merge(farmacie, left_on='Territorio', right_on='DESCRIZIONECOMUNE')\n",
    "\n",
    "df2=joined.drop_duplicates(subset=['Territorio'], keep='first')\n",
    "\n",
    "df3=df2.rename(columns={\"Territorio\": \"Comune\", \"Value\": \"PopolazioneTotale\", \"DESCRIZIONEPROVINCIA\" : \"Provincia\", \"SIGLAPROVINCIA\":\"SiglaProvincia\"})\n",
    "df3.to_csv('comuni_sicilia.csv', columns=['Comune', 'PopolazioneTotale', 'Provincia', 'SiglaProvincia'], index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "89245350",
   "metadata": {},
   "source": [
    "///some comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e305354",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_private = pd.read_csv(\"../datasets/synthesized_&_cleaned/strutture_sanitarie_private.csv\", delimiter=\";\")\n",
    "df_pubbliche = pd.read_csv(\"../datasets/synthesized_&_cleaned/strutture_sanitarie_pubbliche.csv\", on_bad_lines=\"skip\", delimiter=\";\", encoding=\"utf-8\")\n",
    "df_paraf = pd.read_csv(\"../datasets/cleaned/parafarmacie.csv\", on_bad_lines=\"skip\", delimiter=\";\", encoding=\"utf-8\")\n",
    "df_farma = pd.read_csv(\"../datasets/cleaned/farmacie.csv\", on_bad_lines=\"skip\", delimiter=\";\", encoding=\"utf-8\")\n",
    "\n",
    "df_private.columns = df_private.columns.str.strip()\n",
    "df_pubbliche.columns = df_pubbliche.columns.str.strip()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f75e2680",
   "metadata": {},
   "source": [
    "///some comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255ab5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"stv_project\")\n",
    "geocode = RateLimiter(geolocator.geocode) #, min_delay_seconds=0.1\n",
    "\n",
    "LOC = []\n",
    "LAT = []\n",
    "LON = []\n",
    "\n",
    "for via, citta in zip(df_pubbliche[\"Indirizzo\"], df_pubbliche[\"Citta\\'\"]):\n",
    "    \n",
    "    location = geocode(via + \" \" + citta)\n",
    "\n",
    "    if(location is not None):\n",
    "        cap = re.search(r'\\d{5}',location.address)\n",
    "\n",
    "        if cap is not None:\n",
    "            LOC.append(cap.group())\n",
    "        else:\n",
    "            LOC.append(00000)\n",
    "\n",
    "        if location.latitude is not None:\n",
    "            LAT.append(location.latitude)\n",
    "        else:\n",
    "            LAT.append(0.0)\n",
    "\n",
    "        if location.longitude is not None:\n",
    "            LON.append(location.longitude)\n",
    "        else:\n",
    "            LON.append(0.0)\n",
    "            \n",
    "df_private.insert(loc=0, column='CAP', value=pd.Series(LOC))\n",
    "df_private.insert(loc=0, column='LONGITUDINE', value=pd.Series(LON))\n",
    "df_private.insert(loc=0, column='LATITUDINE', value=pd.Series(LAT))\n",
    "\n",
    "filepath = Path('../datasets/private.csv')\n",
    "df_private.to_csv(filepath, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4ed39b14",
   "metadata": {},
   "source": [
    "///some comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"stv_project\")\n",
    "geocode = RateLimiter(geolocator.geocode) #, min_delay_seconds=0.1\n",
    "\n",
    "COM = []\n",
    "LAT = []\n",
    "LON = []\n",
    "\n",
    "for via, cap in zip(df_pubbliche[\"Indirizzo\"], df_pubbliche[\"CAP\"]):\n",
    "\n",
    "    location = geocode(via + \" \" + str(cap))\n",
    "\n",
    "    if(location is not None):\n",
    "        comune = re.search(r'(\\w*), Sicilia', location.address)\n",
    "\n",
    "        if comune is not None:\n",
    "            COM.append(comune[1])\n",
    "        else:\n",
    "            COM.append('######')\n",
    "\n",
    "        if location.latitude is not None:\n",
    "            LAT.append(location.latitude)\n",
    "        else:\n",
    "            LAT.append(0.0)\n",
    "\n",
    "        if location.longitude is not None:\n",
    "            LON.append(location.longitude)\n",
    "        else:\n",
    "            LON.append(0.0)\n",
    "            \n",
    "df_pubbliche.insert(loc=0, column='COMUNE', value=pd.Series(COM))\n",
    "df_pubbliche.insert(loc=0, column='LONGITUDINE', value=pd.Series(LON))\n",
    "df_pubbliche.insert(loc=0, column='LATITUDINE', value=pd.Series(LAT))\n",
    "\n",
    "filepath = Path('../datasets/pubbliche.csv')\n",
    "df_pubbliche.to_csv(filepath, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f108820b",
   "metadata": {},
   "source": [
    "\n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8a8e1e15",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# __4 Trasformazione dei dataset a 5 stelle__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "804fec58",
   "metadata": {},
   "source": [
    "### __4.1 Ontologia__\n",
    "\n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "598e06ae",
   "metadata": {},
   "source": [
    "### __4.2 Creazione grafo RDF__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0da33a5a",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# __5 Data visualization__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "05cf9238",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# __6 Creazione di un'applicazione__\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2e19392e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
